{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a5dfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import key_value\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049e2ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "{'groq': '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', 'open_ai': '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', 'langchain': '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', 'tavily': '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'}\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] =key_value.creds_data[\"groq\"]\n",
    "print(key_value.creds_data[\"groq\"])\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] =key_value.creds_data[\"langchain\"]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "print(key_value.creds_data)\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = key_value.creds_data[\"open_ai\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1f14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "llm=ChatGroq(model_name=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1d23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0571e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "\n",
    "    if session_id not in store:\n",
    "\n",
    "        \n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a40e3b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready to conduct the interview. Here's my first question:\n",
      "\n",
      "**SQL Question 1 (4/5)**\n",
      "What is normalization in a database, and what are its advantages?\n",
      "\n",
      "Please respond with a brief answer.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"new_chat1\"}}\n",
    "model_with_memory=RunnableWithMessageHistory(llm,get_session_history)\n",
    "print(model_with_memory.invoke(('''You are a tech interviewer , you need to interview a candidate for a python developer role with 2.5 yr exp.\n",
    "you have to evaluate the candiate by asking him 5 questions in total on below mentioned topics . based on his ansers rate him out of 10. \n",
    "ask questions where it can be ansered in 2 lines, \n",
    "dont ank to code.\n",
    "topics, difficulty to ask \n",
    "SQL 4/5\n",
    "python 4/5\n",
    "pandas 3/5\n",
    "linux 3/5\n",
    "marks should be awarded liberally. \n",
    "in case you get to know he understand the concept, give good marks. \n",
    "ask 1 question after you recive anser for other .  '''),config=config).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49760c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's correct! You've accurately explained the difference between INNER JOIN and LEFT JOIN. I'd rate this answer 8/10.\n",
      "\n",
      "Here's my next question:\n",
      "\n",
      "**Python Question 1 (4/5)**\n",
      "What is the difference between the `is` and `==` operators in Python?\n",
      "\n",
      "Please respond with a brief answer.\n"
     ]
    }
   ],
   "source": [
    "print(model_with_memory.invoke((\"inner join is used when 2 tables are joined with mathing attributes with respective given column, rows which dosn't find a match are removes from both tables. where as in left join only rows from right table are removed\"),config=config).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01971d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='''You are a tech interviewer , you need to interview a candidate for a python developer role with 2.5 yr exp.\n",
    "you have to evaluate the candiate by asking him 5 questions in total on below mentioned topics . based on his ansers rate him out of 10. \n",
    "ask questions where it can be ansered in 2 lines, \n",
    "dont ank to code.\n",
    "topics, difficulty to ask \n",
    "SQL 4/5\n",
    "python 4/5\n",
    "pandas 3/5\n",
    "linux 3/5\n",
    "marks should be awarded liberally. \n",
    "in case you get to know he understand the concept, give good marks. \n",
    "\n",
    "ask 1 question after you recive anser for other . return the result at the end. \n",
    "example: \n",
    "Question: why do we use pandas? \n",
    "Answer: \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ab83e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's get started with the interview. Here's my first question:\n",
      "\n",
      "**SQL (4/5)**\n",
      "What is the difference between INNER JOIN and LEFT JOIN in SQL? \n",
      "\n",
      "Please respond, and I'll rate your answer and ask the next question.\n",
      "inner join is used when 2 tables are joined with mathing attributes with respective given column, rows which dosn't find a match are removes from both tables. where as in left join only rows from right table are removed\n",
      "inner join is used when 2 tables are joined with mathing attributes with respective given column, rows which dosn't find a match are removes from both tables. where as in left join only rows from right table are removed\n",
      "Good start!\n",
      "\n",
      "I'd rate this answer 7/10. You've correctly explained the basic difference between INNER JOIN and LEFT JOIN, but could have been more precise. INNER JOIN returns only the rows that have a match in both tables, whereas LEFT JOIN returns all the rows from the left table and the matching rows from the right table. If there's no match, the result will contain NULL values for the right table columns.\n",
      "\n",
      "Here's my next question:\n",
      "\n",
      "**Python (4/5)**\n",
      "What is the difference between `is` and `==` operators in Python?\n",
      "i dont know\n",
      "i dont know\n",
      "Don't worry, it's okay! This is a tricky question.\n",
      "\n",
      "I'd rate this answer 2/10, as you didn't provide any information or insight into the difference between `is` and `==`.\n",
      "\n",
      "Here's a brief explanation: `is` checks if two objects are the same (i.e., same memory location), whereas `==` checks if two objects have the same value.\n",
      "\n",
      "Moving on to the next question:\n",
      "\n",
      "**Pandas (3/5)**\n",
      "What is the purpose of the `groupby` function in Pandas?\n",
      "it is used to combine tables based on a column value. we use df.groupby() as syntax.\n",
      "it is used to combine tables based on a column value. we use df.groupby() as syntax.\n",
      "I'd rate this answer 6/10. You're on the right track, but the explanation could be more precise.\n",
      "\n",
      "The `groupby` function is used to split a DataFrame into groups based on some criteria, such as a column value, and then apply a function to each group. It's not exactly about combining tables, but rather about aggregating or transforming data within groups.\n",
      "\n",
      "Here's an example: `df.groupby('column_name').sum()` would group the DataFrame by the values in `column_name` and then calculate the sum for each group.\n",
      "\n",
      "Next question:\n",
      "\n",
      "**Linux (3/5)**\n",
      "What is the purpose of the `grep` command in Linux?\n",
      "it is used to find text where pattern matches.\n",
      "it is used to find text where pattern matches.\n",
      "I'd rate this answer 8/10. You've correctly explained the basic purpose of the `grep` command.\n",
      "\n",
      "`grep` is indeed used to search for patterns in one or more files and print the lines that match those patterns. It's a powerful command for finding specific text or patterns in files.\n",
      "\n",
      "Well done!\n",
      "\n",
      "Next question:\n",
      "\n",
      "**SQL (4/5)**\n",
      "What is the purpose of the `INDEX` in a database table?\n",
      "it is used to retrive information quickly.\n",
      "it is used to retrive information quickly.\n",
      "I'd rate this answer 8/10. You've correctly identified the main benefit of an index in a database table.\n",
      "\n",
      "An index is a data structure that improves the speed of data retrieval by providing a quick way to locate specific data. By indexing a column or set of columns, queries can use the index to quickly locate the desired data, rather than scanning the entire table.\n",
      "\n",
      "You could have elaborated a bit more on how indexes work, but overall, your answer is spot on!\n",
      "\n",
      "That's all 5 questions! Let's tally up the scores:\n",
      "\n",
      "1. SQL (INNER JOIN vs LEFT JOIN): 7/10\n",
      "2. Python (`is` vs `==`): 2/10\n",
      "3. Pandas (`groupby`): 6/10\n",
      "4. Linux (`grep`): 8/10\n",
      "5. SQL (INDEX): 8/10\n",
      "\n",
      "Average score: 6.2/10\n",
      "\n",
      "You've demonstrated a good understanding of the concepts, but could improve on providing more detailed explanations and examples. Overall, it's a solid performance!\n",
      "\n",
      "What do you think? Do you want to simulate another interview or stop here?\n",
      "stop here\n",
      "stop here\n",
      "It was a pleasure simulating an interview with you. I hope you found it helpful in assessing your knowledge and identifying areas for improvement.\n",
      "\n",
      "Remember, the goal of this simulation was to evaluate your understanding of the concepts, not to trip you up with tricky questions. If you have any questions or topics you'd like to discuss, feel free to ask me anytime.\n",
      "\n",
      "Good luck with your real interviews, and I hope you ace them!\n",
      "thank you\n",
      "thank you\n",
      "You're welcome! It was a pleasure helping you with the simulated interview. If you need anything else, feel free to ask. Good luck with your future endeavors!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m9\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_with_memory\u001b[38;5;241m.\u001b[39minvoke((i1),config\u001b[38;5;241m=\u001b[39mconfig)\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m----> 5\u001b[0m     i1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i1)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_with_memory\u001b[38;5;241m.\u001b[39minvoke((i1),config\u001b[38;5;241m=\u001b[39mconfig)\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32mC:\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"new_chat2\"}}\n",
    "i1=prompt\n",
    "for i in range(9):\n",
    "    print(model_with_memory.invoke((i1),config=config).content)\n",
    "    i1=input()\n",
    "    print(i1)\n",
    "print(model_with_memory.invoke((i1),config=config).content)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b67bc62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "\n",
    "# Parameters for recording\n",
    "FORMAT = pyaudio.paInt16   # 16-bit resolution\n",
    "CHANNELS = 1               # Mono audio\n",
    "RATE = 44100               # 44.1kHz sampling rate\n",
    "CHUNK = 1024               # Number of audio frames per buffer\n",
    "RECORD_SECONDS = 10       # Duration of recording\n",
    "OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "# Initialize PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Open the stream for recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Read data from the stream in chunks\n",
    "for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6848cee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wavio in c:\\anaconda3\\lib\\site-packages (0.0.9)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\anaconda3\\lib\\site-packages (from wavio) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\anaconda3\\lib\\site-packages (from scipy) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install wavio\n",
    "! pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cfe400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Finished recording.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import sounddevice as sd\n",
    "devices = sd.query_devices()\n",
    "#print(devices)\n",
    "# Parameters for recording\n",
    "FORMAT = pyaudio.paInt16   # 16-bit resolution\n",
    "CHANNELS = 1          # Mono audio\n",
    "RATE = 44100               # 44.1kHz sampling rate\n",
    "CHUNK = 1024               # Number of audio frames per buffer\n",
    "RECORD_SECONDS = 5     # Duration of recording\n",
    "OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "# Initialize PyAudio\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Open the stream for recording\n",
    "stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,input_device_index=2,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"Recording...\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "# Read data from the stream in chunks\n",
    "for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"Finished recording.\")\n",
    "\n",
    "# Stop and close the stream\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "audio.terminate()\n",
    "\n",
    "# Save the recorded data as a WAV file\n",
    "wf = wave.open(OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d55dbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vosk\n",
      "  Using cached vosk-0.3.45-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: soundfile in c:\\anaconda3\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\anaconda3\\lib\\site-packages (from vosk) (1.16.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from vosk) (2.32.3)\n",
      "Collecting srt (from vosk)\n",
      "  Using cached srt-3.5.3.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\anaconda3\\lib\\site-packages (from vosk) (4.66.4)\n",
      "Requirement already satisfied: websockets in c:\\anaconda3\\lib\\site-packages (from vosk) (14.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from soundfile) (1.26.4)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda3\\lib\\site-packages (from cffi>=1.0->vosk) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests->vosk) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->vosk) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->vosk) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->vosk) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm->vosk) (0.4.6)\n",
      "Using cached vosk-0.3.45-py3-none-win_amd64.whl (14.0 MB)\n",
      "Building wheels for collected packages: srt\n",
      "  Building wheel for srt (setup.py): started\n",
      "  Building wheel for srt (setup.py): finished with status 'done'\n",
      "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22557 sha256=e1f3056f0051df79b986f6c7ba96c7f80662ffd2b9d0cccbf111f4c7fdfe9ae4\n",
      "  Stored in directory: c:\\users\\abhiv\\appdata\\local\\pip\\cache\\wheels\\1f\\43\\f1\\23ee9119497fcb57d9f7046fbf34c6d9027c46a1fa7824cf08\n",
      "Successfully built srt\n",
      "Installing collected packages: srt, vosk\n",
      "Successfully installed srt-3.5.3 vosk-0.3.45\n"
     ]
    }
   ],
   "source": [
    "! pip install vosk soundfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184ba51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: how are you \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import wave\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# Path to your downloaded Vosk model directory\n",
    "model = Model(\"vosk-model-small-en-in-0.4\")\n",
    "\n",
    "# Open the audio file (must be WAV format)\n",
    "wf = wave.open(\"output.wav\", \"rb\")\n",
    "recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "result_text = \"\"\n",
    "while True:\n",
    "    data = wf.readframes(4000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = json.loads(recognizer.Result())\n",
    "        result_text += result.get(\"text\", \"\") + \" \"\n",
    "\n",
    "print(\"Transcription:\", result_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c8eadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\anaconda3\\lib\\site-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\anaconda3\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2024.2.2)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.5.4\n"
     ]
    }
   ],
   "source": [
    "! pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a46e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "\n",
    "text = \"Hello! This is an AI-generated voice using Google TTS.\"\n",
    "tts = gTTS(text=text, lang=\"en\")\n",
    "\n",
    "# Save as an audio file\n",
    "tts.save(\"output_test.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1db5d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7043 sha256=bcca40cdf3fcddb1565eb516ac69049968d44181544e4a9f3e7f80aa973d235d\n",
      "  Stored in directory: c:\\users\\abhiv\\appdata\\local\\pip\\cache\\wheels\\50\\98\\42\\62753a9e1fb97579a0ce2f84f7db4c21c09d03bb2091e6cef4\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    }
   ],
   "source": [
    "! pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20db0727",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_playsoundWin() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaysound\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m playsound\n\u001b[1;32m----> 3\u001b[0m playsound(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_test.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m,device\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: _playsoundWin() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "from playsound import playsound\n",
    "\n",
    "playsound(\"output_test.mp3\",device=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c1c40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import keyboard\n",
    "\n",
    "# Audio settings\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 44100  # Sample rate\n",
    "CHUNK = 1024  # Buffer size\n",
    "OUTPUT_FILENAME = \"recorded_audio.wav\"\n",
    "\n",
    "audio = pyaudio.PyAudio()\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio():\n",
    "    print(\"Press SPACEBAR to start recording...\")\n",
    "    \n",
    "    while True:\n",
    "        keyboard.wait(\"space\")  # Wait for spacebar press\n",
    "        print(\"Recording started... Press SPACEBAR again to stop.\")\n",
    "        \n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True,input_device_index=2,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "\n",
    "        frames = []\n",
    "        \n",
    "        while True:\n",
    "            data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "            frames.append(data)\n",
    "            if keyboard.is_pressed(\"space\"):  # Stop recording on spacebar press\n",
    "                break\n",
    "        \n",
    "        print(\"Recording stopped.\")\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        # Save the recorded audio\n",
    "        wf = wave.open(OUTPUT_FILENAME, \"wb\")\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "        wf.close()\n",
    "        return \n",
    "\n",
    "def audio_text():\n",
    "    wf = wave.open(OUTPUT_FILENAME, \"rb\")\n",
    "    recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "\n",
    "    result_text = \"\"\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            result_text += result.get(\"text\", \"\") + \" \"\n",
    "    return result_text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
